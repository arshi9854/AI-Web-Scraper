# ğŸ•¸ï¸ AI Web Scraper ğŸš€

An intelligent web scraping solution powered by **Ollama**, **BrightData**, **Selenium**, and modern AI tools to extract, parse, and analyze web content in a smart, scalable way.

## ğŸ” Overview

This AI Web Scraper is built to go beyond traditional scraping by integrating Large Language Models (LLMs) using **Ollama** and leveraging **BrightDataâ€™s proxy services** for reliable data extraction. Whether you're scraping e-commerce sites, news articles, or public datasets, this tool gives you an edge with automation and intelligence.

---

## âš™ï¸ Features

- âœ… **Headless Browser Automation** with Selenium
- ğŸ¤– **Natural Language Processing** with LLMs via Ollama
- ğŸŒ **Proxy Rotation** with BrightData for anti-block scraping
- ğŸ§  **AI-Powered Content Filtering** and Semantic Extraction
- ğŸ“„ Save data in **CSV, JSON**, or push to **databases**
- ğŸ› ï¸ Configurable via `config.yaml` or CLI
- ğŸ’¡ Ready for cloud deployment and CI/CD integration

---

## ğŸ§° Tech Stack

| Tool         | Purpose                         |
|--------------|----------------------------------|
| ğŸ Python     | Core programming language        |
| ğŸ§ª Selenium   | Web automation and scraping      |
| ğŸ§  Ollama     | LLM-based intelligent processing |
| ğŸŒ BrightData | Rotating proxies for scraping    |
| ğŸ“¦ BeautifulSoup | HTML parsing                |
| ğŸ¼ Pandas     | Data wrangling & export          |

---
## âš™ï¸ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/arshi9854/AI-Web-Scraper.git
cd AI-Web-Scraper
```
### 2. Install Dependencies

```bash
pip install -r requirements.txt
```
### 3. Configure Settings

- Update the config.yaml or .env file to include your:

- BrightData credentials (proxy host, port, username, password)

- Ollama model and endpoint

- Scraping target URLs or keywords

### 4. Run the Scraper

```bash
python main.py
```
âœ… Make sure BrightData Proxy Manager and Ollama with your selected LLM are running locally or remotely before executing.

### ğŸ§  How It Works

1) Scraper Initialization: Selenium starts a headless browser session for automation.

2) Proxy Assignment: BrightData dynamically rotates IPs and routes requests.

3) Page Parsing: BeautifulSoup extracts required data from HTML.

4) AI Analysis: Content is passed to Ollama, which uses LLMs to summarize, categorize, or interpret results.

5) Data Export: Parsed results are saved as CSV/JSON or pushed to a database.

### ğŸ§ª Example Use Cases

ğŸ›’ E-commerce Scraping: Products, pricing, reviews

ğŸ“° News Aggregation: Summarize articles using AI

ğŸ“Š Data Research: Academic or business intelligence scraping

ğŸ” SEO & Competitor Analysis: Keyword and content monitoring

### ğŸ’¡ Future Improvements

âœ… Dockerize the full stack for easier deployment

âœ… Add GUI or Streamlit Dashboard

âœ… Multi-threaded scraping and rate limiting

âœ… MongoDB or PostgreSQL backend support

âœ… Real-time scraping metrics and logging

âœ… Drag & drop prompt editor for LLM configurations



